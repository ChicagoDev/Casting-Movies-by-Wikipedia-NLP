{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from nlp.models import Tfidf, TopicModelSVD\n",
    "from nlp.util import *\n",
    "from wrangling.cast import CastingPool\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "cpool = CastingPool()\n",
    "\n",
    "\n",
    "## Grab two events\n",
    "event_a = cpool.db.events.find_one({'title': 'Man Lands on the Moon'})\n",
    "event_b = cpool.db.events.find_one({'title': 'OJ Simpson Trial'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab two sets of roles\n",
    "a_roles = cpool.get_roles(event_a['_id'])\n",
    "b_roles = cpool.get_roles(event_b['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab two casting pools\n",
    "#a_cstng_pool = cpool.get_potential_cast(event_a['_id'])\n",
    "#b_cstng_pool = cpool.get_potential_cast(event_b['_id'])\n",
    "\n",
    "#Casting Pool Will Be The Same\n",
    "casting_pool = cpool.get_casting_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Topic Model Cast A, Cast B\n",
    "\n",
    "#docs_a = [p['stemmed_wiki_doc'] for p in a_cstng_pool]\n",
    "#doc_ids_a = [p['_id'] for p in a_cstng_pool]\n",
    "\n",
    "#model_a = Tfidf(docs_a, doc_ids_a)\n",
    "#topic_model_a = TopicModelSVD(model_a.model, model_a.cv_tfidf)\n",
    "\n",
    "\n",
    "#docs_b = [p['stemmed_wiki_doc'] for p in b_cstng_pool]\n",
    "#doc_ids_b = [p['_id'] for p in b_cstng_pool]\n",
    "\n",
    "#model_b = Tfidf(docs_b, doc_ids_b)\n",
    "#topic_model_b = TopicModelSVD(model_b.model, model_b.cv_tfidf)\n",
    "\n",
    "docs_a = [p['clean_doc'] for p in casting_pool]\n",
    "doc_ids_a = [p['_id'] for p in casting_pool]\n",
    "\n",
    "model_a = Tfidf(docs_a, doc_ids_a)\n",
    "topic_model = TopicModelSVD(model_a.model, model_a.cv_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Topic Model Roles A, Roles B\n",
    "\n",
    "a_roles_topic_mdl = get_SVD_model(a_roles)\n",
    "#b_roles_topic_mdl = get_SVD_model(b_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cluster\n",
    "cpool_a_kmeans = KMeans(n_clusters=10)\n",
    "#cpool_b_kmeans = KMeans(n_clusters=10)\n",
    "\n",
    "cpool_a_kmeans.fit(model_a.model)\n",
    "#cpool_b_kmeans.fit(model_b.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_roles_tfidf, a_roles_topics = get_SVD_model(a_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablation</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abort</th>\n",
       "      <th>aborted</th>\n",
       "      <th>abraham</th>\n",
       "      <th>...</th>\n",
       "      <th>القمر</th>\n",
       "      <th>انشقاق</th>\n",
       "      <th>に野口聡一</th>\n",
       "      <th>ぴあ映画生活</th>\n",
       "      <th>オルドリンが出演</th>\n",
       "      <th>バズ</th>\n",
       "      <th>宇宙兄弟</th>\n",
       "      <th>小栗旬</th>\n",
       "      <th>岡田将生主演</th>\n",
       "      <th>玉兔</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5c75dbadfc0c4b2a44860227</th>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.007741</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5c75dbadfc0c4b2a44860228</th>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5c75dbadfc0c4b2a44860229</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5c75dbadfc0c4b2a4486022a</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 5399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                aa  abbreviated       abc   ability  ablation  \\\n",
       "5c75dbadfc0c4b2a44860227  0.004781     0.009096  0.000000  0.003032  0.000000   \n",
       "5c75dbadfc0c4b2a44860228  0.005716     0.000000  0.003625  0.000000  0.000000   \n",
       "5c75dbadfc0c4b2a44860229  0.000000     0.000000  0.000000  0.000000  0.000000   \n",
       "5c75dbadfc0c4b2a4486022a  0.000000     0.000000  0.000000  0.000000  0.003222   \n",
       "\n",
       "                              able    aboard     abort   aborted   abraham  \\\n",
       "5c75dbadfc0c4b2a44860227  0.003870  0.007741  0.015159  0.004781  0.000000   \n",
       "5c75dbadfc0c4b2a44860228  0.002314  0.004627  0.000000  0.000000  0.076123   \n",
       "5c75dbadfc0c4b2a44860229  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5c75dbadfc0c4b2a4486022a  0.002056  0.002056  0.000000  0.002540  0.000000   \n",
       "\n",
       "                            ...        القمر    انشقاق     に野口聡一    ぴあ映画生活  \\\n",
       "5c75dbadfc0c4b2a44860227    ...     0.000000  0.000000  0.000000  0.000000   \n",
       "5c75dbadfc0c4b2a44860228    ...     0.000000  0.000000  0.003625  0.003625   \n",
       "5c75dbadfc0c4b2a44860229    ...     0.000000  0.000000  0.000000  0.000000   \n",
       "5c75dbadfc0c4b2a4486022a    ...     0.003222  0.003222  0.000000  0.000000   \n",
       "\n",
       "                          オルドリンが出演        バズ      宇宙兄弟       小栗旬    岡田将生主演  \\\n",
       "5c75dbadfc0c4b2a44860227  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5c75dbadfc0c4b2a44860228  0.003625  0.003625  0.003625  0.003625  0.003625   \n",
       "5c75dbadfc0c4b2a44860229  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5c75dbadfc0c4b2a4486022a  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                玉兔  \n",
       "5c75dbadfc0c4b2a44860227  0.000000  \n",
       "5c75dbadfc0c4b2a44860228  0.000000  \n",
       "5c75dbadfc0c4b2a44860229  0.000000  \n",
       "5c75dbadfc0c4b2a4486022a  0.003222  \n",
       "\n",
       "[4 rows x 5399 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_roles_tfidf.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neil Armstrong's id is: 5c75dbadfc0c4b2a44860227\n",
      "Buzz Aldrin's id is: 5c75dbadfc0c4b2a44860228\n",
      "Michael Collins \\(astronaut\\)'s id is: 5c75dbadfc0c4b2a44860229\n",
      "Moon's id is: 5c75dbadfc0c4b2a4486022a\n"
     ]
    }
   ],
   "source": [
    "for role in a_roles:\n",
    "    print (role['name'] + '\\'s id is: ' + str(role['_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a cluster, but also translates clean text to proper vector-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform Roles A & B accoring to models of Roles:\n",
    "import pandas as pd\n",
    "\n",
    "docs_a_r = [p['clean_doc'] for p in a_roles]\n",
    "doc_ids_a_r = [p['_id'] for p in a_roles]\n",
    "\n",
    "a_roles_transformed = model_a.cv_tfidf.transform(docs_a_r).toarray()\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "#for role in a_roles:\n",
    "#    cpool_a_kmeans.predict(np.array(a_roles_transformed.loc[role['_id']]).reshape(1,-1))\n",
    "cpool_a_kmeans.predict(np.array(a_roles_transformed[0]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Lerner (actor) chosen to play Greg Gumbel\n"
     ]
    }
   ],
   "source": [
    "#Greg Gumbel was placed in group 9. Choose a random candidate to play him in the movie. \n",
    "candidates = []\n",
    "for i in zip(cpool_a_kmeans.labels_, a_cstng_pool):\n",
    "    if i[0] == 9:\n",
    "        candidates.append((i[1]['name']))\n",
    "\n",
    "print (f'{np.random.choice(candidates)} chosen to play Greg Gumbel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given a person and cluster, gives the best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom Cruise 0.024861821529126554\n",
      "Robert De Niro 0.025993339460747677\n",
      "Anthony Hopkins 0.02740181802737521\n",
      "Tom Hanks 0.04409065718578947\n",
      "Robert Duvall 0.04578903560948069\n",
      "Judy Garland 0.09485885507881404\n",
      "Judy Garland\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_ = -np.inf\n",
    "name = ''\n",
    "person = None\n",
    "for i in zip(cpool_a_kmeans.labels_, casting_pool):\n",
    "    \n",
    "    #Serach the correct cluster\n",
    "    if i[0] == 8:\n",
    "        \n",
    "        #a_roles_transformed is a role\n",
    "        #model_a is the casting pool vector tfdidf\n",
    "        dist = cosine_distance(np.array(a_roles_transformed[0]), model_a.model.loc[i[1]['_id']])\n",
    "        \n",
    "        if dist > min_:\n",
    "            min_ = dist\n",
    "            name = i[1]['name']\n",
    "            person = i[1]\n",
    "            print(name + ' ' + str(dist))\n",
    "            \n",
    "print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neil Armstrong & Buzz Aldrin - Judy Garland, Michael Collins - Merlin the Magic Mouse, Sam Rockwell - Moon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "film, award, best, actress, actor, nominated, supporting, role, critics, edit\n",
      "\n",
      "Topic  1\n",
      "album, music, band, released, song, single, tour, billboard, songs, parser\n",
      "\n",
      "Topic  2\n",
      "streep, parser, mw, output, quotebox, cs, bugs, film, hoffman, looney\n",
      "\n",
      "Topic  3\n",
      "bugs, looney, bunny, tunes, daffy, duck, porky, sylvester, tweety, cartoon\n",
      "\n",
      "Topic  4\n",
      "cs, parser, mw, output, lock, moore, svg, williams, em, winslet\n"
     ]
    }
   ],
   "source": [
    "topic_model.display_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bson.objectid import ObjectId\n",
    "greg_gumbel = ObjectId('5c6f04ccfc0c4b94ecceef0e')\n",
    "a_roles_tfidf.model.loc[greg_gumbel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(u, v):\n",
    "    \"\"\"\n",
    "    Returns the cosine of the angle between vectors v and u. This is equal to\n",
    "    u.v / |u||v|.\n",
    "    \"\"\"\n",
    "    return numpy.dot(u, v) / (math.sqrt(numpy.dot(u, u)) * math.sqrt(numpy.dot(v, v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp.models import Tfidf, TopicModelSVD\n",
    "\n",
    "def get_SVD_model(people):\n",
    "    print(people)\n",
    "    \n",
    "    docs = [p['clean_doc'] for p in people]\n",
    "    doc_ids = [p['_id'] for p in people]\n",
    "    \n",
    "    model = Tfidf(docs, doc_ids)\n",
    "    topic_model = TopicModelSVD(model.model, model.cv_tfidf)\n",
    "    \n",
    "    return (model, topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast = cpool.get_casting_pool()\n",
    "docs = [p['stemmed_wiki_doc'] for p in cast]\n",
    "doc_ids = [p['_id'] for p in cast]\n",
    "\n",
    "\n",
    "\n",
    "model = Tfidf(docs, doc_ids)\n",
    "topic_model = TopicModelSVD(model.model, model.cv_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = TopicModelSVD(model.model, model.cv_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "means = KMeans(n_clusters=15, random_state=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = KMeans(n_clusters=15, random_state=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
       "        init_size=None, max_iter=100, max_no_improvement=10, n_clusters=20,\n",
       "        n_init=3, random_state=51, reassignment_ratio=0.01, tol=0.0,\n",
       "        verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means.fit(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738.669601596358"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060, 80806)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.model).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-291b21bac8de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, sample_weight)\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster_centers_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels_inertia_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mexpected_n_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "means.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter O'Toole 0.12631355092771873\n",
      "Richard Burton 0.1330834600937386\n",
      "Laurence Olivier 0.1361747203832702\n",
      "Rod Steiger 0.14307874182390548\n",
      "James Earl Jones 0.14677735250988222\n",
      "Woody Allen 0.14899710934935617\n",
      "Jeff Bridges 0.17907671371299091\n",
      "Robin Williams 0.1797301772873159\n",
      "Will Smith 0.24539435597755532\n",
      "Samuel L. Jackson 0.4274059203214055\n",
      "Samuel L. Jackson\n"
     ]
    }
   ],
   "source": [
    "min_ = -np.inf\n",
    "name = ''\n",
    "person = None\n",
    "for i in zip(cpool_a_kmeans.labels_, a_cstng_pool):\n",
    "    \n",
    "    #Serach the correct cluster\n",
    "    #if i[0] == 0:\n",
    "        \n",
    "    #a_roles_transformed is a role\n",
    "    #model_a is the casting pool vector tfdidf\n",
    "    dist = cosine_distance(np.array(a_roles_transformed[0]), model_a.model.loc[i[1]['_id']])\n",
    "\n",
    "    if dist > min_:\n",
    "        min_ = dist\n",
    "        name = i[1]['name']\n",
    "        person = i[1]\n",
    "        print(name + ' ' + str(dist))\n",
    "\n",
    "print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import common_texts\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "import gensim.models.doc2vec\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['human', 'interface', 'computer'], tags=[0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [TaggedDocument(person['stemmed_wiki_doc'].split(), [person['_id']]) for person in a_cstng_pool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(docs, vector_size=5, window=2, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 OSX",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
